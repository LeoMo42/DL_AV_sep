{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL2_av_sep.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wl5aZThEu84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "16b1ada7-65c0-4352-df19-559062dac3c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9J4iGoE53n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ./gdrive/My\\ Drive/DL2/DL_AV_sep/DL_AV_sep.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC1Q6X1yPdKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ./gdrive/My\\ Drive/DL2/DL_AV_sep/data.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsrcCFJgFI23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3b8434b-628c-4210-ff92-eb4e2b721a1d"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.6.3)\n",
            "Requirement already satisfied: numba==0.48 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.48.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.0.5)\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (2.3.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (7.0.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (2.1.8)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48->-r requirements.txt (line 2)) (47.3.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.48->-r requirements.txt (line 2)) (0.31.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn->-r requirements.txt (line 4)) (4.1.2.30)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.34.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.30.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 7)) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (1.6.0.post3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (4.1.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->-r requirements.txt (line 5)) (3.1.0)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV2ZCjPxFQVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbc785a6-1292-4638-f79a-69dc2dfc15a9"
      },
      "source": [
        "!python setup.py develop"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "creating av_sep.egg-info\n",
            "writing av_sep.egg-info/PKG-INFO\n",
            "writing dependency_links to av_sep.egg-info/dependency_links.txt\n",
            "writing requirements to av_sep.egg-info/requires.txt\n",
            "writing top-level names to av_sep.egg-info/top_level.txt\n",
            "writing manifest file 'av_sep.egg-info/SOURCES.txt'\n",
            "reading manifest file 'av_sep.egg-info/SOURCES.txt'\n",
            "writing manifest file 'av_sep.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/av-sep.egg-link (link to .)\n",
            "Adding av-sep 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content\n",
            "Processing dependencies for av-sep==0.0.1\n",
            "Searching for Pillow==7.0.0\n",
            "Best match: Pillow 7.0.0\n",
            "Adding Pillow 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras==2.3.1\n",
            "Best match: Keras 2.3.1\n",
            "Adding Keras 2.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==2.2.0\n",
            "Best match: tensorflow 2.2.0\n",
            "Adding tensorflow 2.2.0 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for mtcnn==0.1.0\n",
            "Best match: mtcnn 0.1.0\n",
            "Adding mtcnn 0.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pandas==1.0.5\n",
            "Best match: pandas 1.0.5\n",
            "Adding pandas 1.0.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numba==0.48.0\n",
            "Best match: numba 0.48.0\n",
            "Adding numba 0.48.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for librosa==0.6.3\n",
            "Best match: librosa 0.6.3\n",
            "Adding librosa 0.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.5\n",
            "Best match: numpy 1.18.5\n",
            "Adding numpy 1.18.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.2.0\n",
            "Best match: kiwisolver 1.2.0\n",
            "Adding kiwisolver 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.30.0\n",
            "Best match: grpcio 1.30.0\n",
            "Adding grpcio 1.30.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opt-einsum==3.2.1\n",
            "Best match: opt-einsum 3.2.1\n",
            "Adding opt-einsum 3.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.34.2\n",
            "Best match: wheel 0.34.2\n",
            "Adding wheel 0.34.2 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==2.2.0\n",
            "Best match: tensorflow-estimator 2.2.0\n",
            "Adding tensorflow-estimator 2.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==2.2.2\n",
            "Best match: tensorboard 2.2.2\n",
            "Adding tensorboard 2.2.2 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.9.0\n",
            "Best match: absl-py 0.9.0\n",
            "Adding absl-py 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.12.1\n",
            "Best match: wrapt 1.12.1\n",
            "Adding wrapt 1.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.10.0\n",
            "Best match: protobuf 3.10.0\n",
            "Adding protobuf 3.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.3.3\n",
            "Best match: gast 0.3.3\n",
            "Adding gast 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opencv-python==4.1.2.30\n",
            "Best match: opencv-python 4.1.2.30\n",
            "Adding opencv-python 4.1.2.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for llvmlite==0.31.0\n",
            "Best match: llvmlite 0.31.0\n",
            "Adding llvmlite 0.31.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==47.3.1\n",
            "Best match: setuptools 47.3.1\n",
            "Adding setuptools 47.3.1 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for audioread==2.1.8\n",
            "Best match: audioread 2.1.8\n",
            "Adding audioread 2.1.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.15.1\n",
            "Best match: joblib 0.15.1\n",
            "Adding joblib 0.15.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for resampy==0.2.2\n",
            "Best match: resampy 0.2.2\n",
            "Adding resampy 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for decorator==4.4.2\n",
            "Best match: decorator 4.4.2\n",
            "Adding decorator 4.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.1\n",
            "Best match: google-auth-oauthlib 0.4.1\n",
            "Adding google-auth-oauthlib 0.4.1 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.2.2\n",
            "Best match: Markdown 3.2.2\n",
            "Adding Markdown 3.2.2 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-auth==1.17.2\n",
            "Best match: google-auth 1.17.2\n",
            "Adding google-auth 1.17.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.6.0.post3\n",
            "Best match: tensorboard-plugin-wit 1.6.0.post3\n",
            "Adding tensorboard-plugin-wit 1.6.0.post3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests-oauthlib==1.3.0\n",
            "Best match: requests-oauthlib 1.3.0\n",
            "Adding requests-oauthlib 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.6.20\n",
            "Best match: certifi 2020.6.20\n",
            "Adding certifi 2020.6.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.9\n",
            "Best match: idna 2.9\n",
            "Adding idna 2.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for importlib-metadata==1.6.1\n",
            "Best match: importlib-metadata 1.6.1\n",
            "Adding importlib-metadata 1.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cachetools==4.1.0\n",
            "Best match: cachetools 4.1.0\n",
            "Adding cachetools 4.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for rsa==4.6\n",
            "Best match: rsa 4.6\n",
            "Adding rsa 4.6 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for oauthlib==3.1.0\n",
            "Best match: oauthlib 3.1.0\n",
            "Adding oauthlib 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for zipp==3.1.0\n",
            "Best match: zipp 3.1.0\n",
            "Adding zipp 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for av-sep==0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgr04LqXF1q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/52142671/google-colab-redirect-python-output-to-a-log-file\n",
        "!python tree_text_gen/binary/translation/train.py --expr-name baseline_20200525-3 --datadir ./iwslt/IWSLT/en-de/ --model-type translation --beta-burnin 2 --beta-step 0.05 --self-teach-beta-step 0.05 --log-base-dir gdrive/My\\ Drive/RL_proj/output/checkpoints 2>&1 | tee translation_new_oracle_logs.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGbe2Gz9QXOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d5ff733-5515-46bb-f967-3164a29a35cd"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkNCyDPuQo__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9006bbc2-4b93-46d0-e077-c098d65f1e46"
      },
      "source": [
        "from av_sep.models.model_v2.AV_train import AvTrain\n",
        "AvTrain.run(\"/content/data/\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as_0: (None, 298, 257, 2)\n",
            "as_1: (None, 298, 257, 96)\n",
            "as_2: (None, 298, 257, 96)\n",
            "as_3: (None, 298, 257, 96)\n",
            "as_4: (None, 298, 257, 96)\n",
            "as_5: (None, 298, 257, 96)\n",
            "as_6: (None, 298, 257, 96)\n",
            "as_7: (None, 298, 257, 96)\n",
            "as_8: (None, 298, 257, 96)\n",
            "as_9: (None, 298, 257, 96)\n",
            "as_10: (None, 298, 257, 96)\n",
            "as_11: (None, 298, 257, 96)\n",
            "as_12: (None, 298, 257, 96)\n",
            "as_13: (None, 298, 257, 96)\n",
            "as_14: (None, 298, 257, 96)\n",
            "as_15: (None, 298, 257, 8)\n",
            "AS_out: (None, 298, 2056)\n",
            "AVfusion: (None, 298, 2568)\n",
            "lstm: (None, 298, 400)\n",
            "fc1: (None, 298, 600)\n",
            "fc2: (None, 298, 600)\n",
            "fc3: (None, 298, 600)\n",
            "complex_mask: (None, 298, 1028)\n",
            "complex_mask_out: (None, 298, 257, 2, 2)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 298, 257, 2)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "as_conv1 (Conv2D)               (None, 298, 257, 96) 1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 298, 257, 96) 384         as_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv2 (Conv2D)               (None, 298, 257, 96) 64608       re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 298, 257, 96) 384         as_conv2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv3 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 298, 257, 96) 384         as_conv3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv4 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 298, 257, 96) 384         as_conv4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv5 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 298, 257, 96) 384         as_conv5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv6 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 298, 257, 96) 384         as_conv6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv7 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 298, 257, 96) 384         as_conv7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv8 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 298, 257, 96) 384         as_conv8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv9 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 298, 257, 96) 384         as_conv9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv10 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 298, 257, 96) 384         as_conv10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv11 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 298, 257, 96) 384         as_conv11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv12 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 298, 257, 96) 384         as_conv12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv13 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 298, 257, 96) 384         as_conv13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv14 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 298, 257, 96) 384         as_conv14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv15 (Conv2D)              (None, 298, 257, 8)  776         re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 298, 257, 8)  32          as_conv15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 75, 1, 1792,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 298, 257, 8)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 75, 1, 1792)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 75, 1, 1792)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 298, 2056)    0           re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 298, 256)     4857344     lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 298, 2568)    0           reshape_1[0][0]                  \n",
            "                                                                 sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 298, 2568)    0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 298, 400)     9500800     time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 298, 600)     240600      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fc2 (Dense)                     (None, 298, 600)     360600      fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "fc3 (Dense)                     (None, 298, 600)     360600      fc2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "complex_mask (Dense)            (None, 298, 1028)    617828      fc3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 298, 257, 2,  0           complex_mask[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 18,775,956\n",
            "Trainable params: 18,770,180\n",
            "Non-trainable params: 5,776\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n",
            "328/328 [==============================] - 544s 2s/step - loss: 0.7056 - val_loss: 0.5599\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.55989, saving model to /content/data/saved_AV_models/AVmodel-2p-001-0.55989.h5\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 1e-05.\n",
            "328/328 [==============================] - 527s 2s/step - loss: 0.6005 - val_loss: 0.5635\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.55989\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 1e-05.\n",
            "328/328 [==============================] - 526s 2s/step - loss: 0.5970 - val_loss: 0.6461\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.55989\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 1e-05.\n",
            "328/328 [==============================] - 527s 2s/step - loss: 0.5839 - val_loss: 0.3833\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.55989 to 0.38334, saving model to /content/data/saved_AV_models/AVmodel-2p-004-0.38334.h5\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 1e-05.\n",
            "328/328 [==============================] - 527s 2s/step - loss: 0.5390 - val_loss: 0.4319\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.38334\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "328/328 [==============================] - 525s 2s/step - loss: 0.5161 - val_loss: 0.5472\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.38334\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "328/328 [==============================] - 523s 2s/step - loss: 0.5103 - val_loss: 0.7090\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.38334\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "328/328 [==============================] - 502s 2s/step - loss: 0.5082 - val_loss: 0.6974\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.38334\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.5044 - val_loss: 0.5518\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.38334\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "328/328 [==============================] - 492s 2s/step - loss: 0.5029 - val_loss: 0.6276\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.38334\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.5016 - val_loss: 0.5510\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.38334\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 490s 1s/step - loss: 0.4997 - val_loss: 0.3517\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.38334 to 0.35168, saving model to /content/data/saved_AV_models/AVmodel-2p-012-0.35168.h5\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 493s 2s/step - loss: 0.4992 - val_loss: 0.4674\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.35168\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 493s 2s/step - loss: 0.4985 - val_loss: 0.4962\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.35168\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 490s 1s/step - loss: 0.4980 - val_loss: 0.5514\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.35168\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.4979 - val_loss: 0.4803\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.35168\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 489s 1s/step - loss: 0.4967 - val_loss: 0.6276\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.35168\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.4964 - val_loss: 0.5927\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.35168\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.4954 - val_loss: 0.4363\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.35168\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 493s 2s/step - loss: 0.4949 - val_loss: 0.5956\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.35168\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 490s 1s/step - loss: 0.4944 - val_loss: 0.6736\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.35168\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 494s 2s/step - loss: 0.4937 - val_loss: 0.4181\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.35168\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 503s 2s/step - loss: 0.4931 - val_loss: 0.6439\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.35168\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 507s 2s/step - loss: 0.4924 - val_loss: 0.4405\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.35168\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 508s 2s/step - loss: 0.4924 - val_loss: 0.5416\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.35168\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 505s 2s/step - loss: 0.4917 - val_loss: 0.4893\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.35168\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 509s 2s/step - loss: 0.4914 - val_loss: 0.6171\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.35168\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 509s 2s/step - loss: 0.4908 - val_loss: 0.5063\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.35168\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4903 - val_loss: 0.6329\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.35168\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 512s 2s/step - loss: 0.4899 - val_loss: 0.5211\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.35168\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4893 - val_loss: 0.3816\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.35168\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4890 - val_loss: 0.4444\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.35168\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4883 - val_loss: 0.5211\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.35168\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 511s 2s/step - loss: 0.4881 - val_loss: 0.7142\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.35168\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 511s 2s/step - loss: 0.4875 - val_loss: 0.5173\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.35168\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 522s 2s/step - loss: 0.4872 - val_loss: 0.3863\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.35168\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 511s 2s/step - loss: 0.4867 - val_loss: 0.6178\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.35168\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 512s 2s/step - loss: 0.4861 - val_loss: 0.4377\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.35168\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 513s 2s/step - loss: 0.4857 - val_loss: 0.4201\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.35168\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 517s 2s/step - loss: 0.4848 - val_loss: 0.5181\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.35168\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4843 - val_loss: 0.4814\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.35168\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 513s 2s/step - loss: 0.4838 - val_loss: 0.2832\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.35168 to 0.28321, saving model to /content/data/saved_AV_models/AVmodel-2p-042-0.28321.h5\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 513s 2s/step - loss: 0.4831 - val_loss: 0.5368\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.28321\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 513s 2s/step - loss: 0.4824 - val_loss: 0.4772\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.28321\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 512s 2s/step - loss: 0.4818 - val_loss: 0.6839\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.28321\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 512s 2s/step - loss: 0.4809 - val_loss: 0.4310\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.28321\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4803 - val_loss: 0.4046\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.28321\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 515s 2s/step - loss: 0.4794 - val_loss: 0.6019\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.28321\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 515s 2s/step - loss: 0.4788 - val_loss: 0.3487\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.28321\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 506s 2s/step - loss: 0.4777 - val_loss: 0.5918\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.28321\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 504s 2s/step - loss: 0.4768 - val_loss: 0.5034\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.28321\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 505s 2s/step - loss: 0.4759 - val_loss: 0.4817\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.28321\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 505s 2s/step - loss: 0.4751 - val_loss: 0.6606\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.28321\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4741 - val_loss: 0.5187\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.28321\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 500s 2s/step - loss: 0.4732 - val_loss: 0.6115\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.28321\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 499s 2s/step - loss: 0.4724 - val_loss: 0.5582\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.28321\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 504s 2s/step - loss: 0.4714 - val_loss: 0.6287\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.28321\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4706 - val_loss: 0.4182\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.28321\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 502s 2s/step - loss: 0.4698 - val_loss: 0.6547\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.28321\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 504s 2s/step - loss: 0.4688 - val_loss: 0.5269\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.28321\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 506s 2s/step - loss: 0.4682 - val_loss: 0.4784\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.28321\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 506s 2s/step - loss: 0.4673 - val_loss: 0.3266\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.28321\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 503s 2s/step - loss: 0.4665 - val_loss: 0.6082\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.28321\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 506s 2s/step - loss: 0.4660 - val_loss: 0.3897\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.28321\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 502s 2s/step - loss: 0.4652 - val_loss: 0.4511\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.28321\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 503s 2s/step - loss: 0.4646 - val_loss: 0.6249\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.28321\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 506s 2s/step - loss: 0.4640 - val_loss: 0.2229\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.28321 to 0.22288, saving model to /content/data/saved_AV_models/AVmodel-2p-067-0.22288.h5\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 505s 2s/step - loss: 0.4634 - val_loss: 0.4781\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.22288\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 508s 2s/step - loss: 0.4629 - val_loss: 0.3867\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.22288\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4624 - val_loss: 0.4005\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.22288\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4619 - val_loss: 0.5350\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.22288\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 500s 2s/step - loss: 0.4613 - val_loss: 0.4476\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.22288\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 495s 2s/step - loss: 0.4609 - val_loss: 0.4167\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.22288\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 490s 1s/step - loss: 0.4603 - val_loss: 0.3274\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.22288\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 490s 1s/step - loss: 0.4599 - val_loss: 0.4417\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.22288\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 517s 2s/step - loss: 0.4596 - val_loss: 0.4225\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.22288\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4591 - val_loss: 0.4978\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.22288\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4588 - val_loss: 0.5071\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.22288\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 489s 1s/step - loss: 0.4584 - val_loss: 0.3959\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.22288\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 492s 1s/step - loss: 0.4579 - val_loss: 0.4117\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.22288\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 488s 1s/step - loss: 0.4577 - val_loss: 0.4661\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.22288\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 485s 1s/step - loss: 0.4574 - val_loss: 0.4110\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.22288\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 488s 1s/step - loss: 0.4571 - val_loss: 0.4778\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.22288\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 501s 2s/step - loss: 0.4567 - val_loss: 0.3265\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.22288\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4565 - val_loss: 0.3064\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.22288\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 518s 2s/step - loss: 0.4561 - val_loss: 0.5188\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.22288\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 522s 2s/step - loss: 0.4559 - val_loss: 0.4740\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.22288\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 517s 2s/step - loss: 0.4556 - val_loss: 0.4920\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.22288\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 515s 2s/step - loss: 0.4553 - val_loss: 0.4002\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.22288\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 508s 2s/step - loss: 0.4550 - val_loss: 0.4330\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.22288\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 493s 2s/step - loss: 0.4549 - val_loss: 0.4222\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.22288\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 493s 2s/step - loss: 0.4546 - val_loss: 0.3768\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.22288\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 489s 1s/step - loss: 0.4542 - val_loss: 0.4737\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.22288\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.4543 - val_loss: 0.2583\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.22288\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.4540 - val_loss: 0.3533\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.22288\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 490s 1s/step - loss: 0.4536 - val_loss: 0.4140\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.22288\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 491s 1s/step - loss: 0.4534 - val_loss: 0.4548\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.22288\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 500s 2s/step - loss: 0.4533 - val_loss: 0.4294\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.22288\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 508s 2s/step - loss: 0.4530 - val_loss: 0.5476\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.22288\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "328/328 [==============================] - 510s 2s/step - loss: 0.4528 - val_loss: 0.3499\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.22288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeS15h0Ny_Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}