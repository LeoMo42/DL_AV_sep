{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL2_av_sep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wl5aZThEu84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9J4iGoE53n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ./gdrive/My\\ Drive/DL2/DL_AV_sep/DL_AV_sep.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC1Q6X1yPdKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ./gdrive/My\\ Drive/DL2/DL_AV_sep/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsrcCFJgFI23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV2ZCjPxFQVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BU0q7KFr4h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rootpath = \"/content/gdrive/My Drive/DL2/DL_AV_sep/data/\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcSlPoSE80dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install youtube-dl\n",
        "!apt install ffmpeg\n",
        "!apt -qq install -y sox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZNL7KGMW88u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from av_sep.preprocessing.audio.audio_downloader import AudioDownloader\n",
        "from av_sep.preprocessing.audio.audio_norm import AudioNorm\n",
        "from av_sep.preprocessing.audio.build_audio_database import AudioDatabaseBuilder\n",
        "\n",
        "from av_sep.preprocessing.av_log.gentxtnew import GenLogs\n",
        "\n",
        "import av_sep.preprocessing.lib.AVHandler as avh\n",
        "\n",
        "from av_sep.preprocessing.video.video_download import VideoDownloader\n",
        "from av_sep.preprocessing.video.MTCNN_detect import MtcnnDetector\n",
        "from av_sep.preprocessing.video.frame_inspector import FrameInspector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IMZOwbGsADk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    av_range = (0, 1000)\n",
        "    max_num_sample = 50000\n",
        "\n",
        "    avh.mkdir(rootpath + 'audio')\n",
        "    avh.mkdir(rootpath + 'video')\n",
        "\n",
        "    # Download audio data\n",
        "    AudioDownloader.run(rootpath, av_range)\n",
        "\n",
        "    # Normalize audio data\n",
        "    AudioNorm.run(rootpath, av_range)\n",
        "    \n",
        "    # Download visual data\n",
        "    VideoDownloader.run(rootpath, av_range)\n",
        "\n",
        "    # Detect and Crop face\n",
        "    MtcnnDetector.run(rootpath, av_range)\n",
        "    FrameInspector.run(rootpath, av_range)\n",
        "    \n",
        "    # Create audio database\n",
        "    AudioDatabaseBuilder.run(rootpath, av_range, max_num_sample)\n",
        "\n",
        "    # Generate log file for data generator\n",
        "    GenLogs.run(rootpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCuvJVA4sCqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from av_sep.models.pretrain_model.pretrain_load_test import LoadPretrained\n",
        "\n",
        "LoadPretrained.run(rootpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3pj7yOVVRHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39fa1347-fe35-424a-d188-8dd171440ba2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Dense, Convolution2D, Bidirectional, concatenate\n",
        "from keras.layers import Flatten, BatchNormalization, ReLU, Reshape, Lambda, TimeDistributed\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.initializers import he_normal, glorot_uniform\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from av_sep.models.lib.MyGenerator import AVGenerator\n",
        "\n",
        "\n",
        "def AV_model(people_num=2):\n",
        "    def UpSampling2DBilinear(size):\n",
        "        return Lambda(lambda x: tf.image.resize(x, size))\n",
        "\n",
        "    def sliced(x, index):\n",
        "        return x[..., index]\n",
        "\n",
        "    # --------------------------- AS start ---------------------------\n",
        "    audio_input = Input(shape=(298, 257, 2))\n",
        "    print('as_0:', audio_input.shape)\n",
        "    as_conv1 = Convolution2D(96, kernel_size=(1, 7), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv1')(audio_input)\n",
        "    as_conv1 = BatchNormalization()(as_conv1)\n",
        "    as_conv1 = ReLU()(as_conv1)\n",
        "    print('as_1:', as_conv1.shape)\n",
        "\n",
        "    as_conv2 = Convolution2D(96, kernel_size=(7, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv2')(as_conv1)\n",
        "    as_conv2 = BatchNormalization()(as_conv2)\n",
        "    as_conv2 = ReLU()(as_conv2)\n",
        "    print('as_2:', as_conv2.shape)\n",
        "\n",
        "    as_conv3 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv3')(as_conv2)\n",
        "    as_conv3 = BatchNormalization()(as_conv3)\n",
        "    as_conv3 = ReLU()(as_conv3)\n",
        "    print('as_3:', as_conv3.shape)\n",
        "\n",
        "    as_conv4 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(2, 1), name='as_conv4')(as_conv3)\n",
        "    as_conv4 = BatchNormalization()(as_conv4)\n",
        "    as_conv4 = ReLU()(as_conv4)\n",
        "    print('as_4:', as_conv4.shape)\n",
        "\n",
        "    as_conv5 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(4, 1), name='as_conv5')(as_conv4)\n",
        "    as_conv5 = BatchNormalization()(as_conv5)\n",
        "    as_conv5 = ReLU()(as_conv5)\n",
        "    print('as_5:', as_conv5.shape)\n",
        "\n",
        "    as_conv6 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(8, 1), name='as_conv6')(as_conv5)\n",
        "    as_conv6 = BatchNormalization()(as_conv6)\n",
        "    as_conv6 = ReLU()(as_conv6)\n",
        "    print('as_6:', as_conv6.shape)\n",
        "\n",
        "    as_conv7 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(16, 1), name='as_conv7')(as_conv6)\n",
        "    as_conv7 = BatchNormalization()(as_conv7)\n",
        "    as_conv7 = ReLU()(as_conv7)\n",
        "    print('as_7:', as_conv7.shape)\n",
        "\n",
        "    as_conv8 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(32, 1), name='as_conv8')(as_conv7)\n",
        "    as_conv8 = BatchNormalization()(as_conv8)\n",
        "    as_conv8 = ReLU()(as_conv8)\n",
        "    print('as_8:', as_conv8.shape)\n",
        "\n",
        "    as_conv9 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv9')(as_conv8)\n",
        "    as_conv9 = BatchNormalization()(as_conv9)\n",
        "    as_conv9 = ReLU()(as_conv9)\n",
        "    print('as_9:', as_conv9.shape)\n",
        "\n",
        "    as_conv10 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(2, 2), name='as_conv10')(as_conv9)\n",
        "    as_conv10 = BatchNormalization()(as_conv10)\n",
        "    as_conv10 = ReLU()(as_conv10)\n",
        "    print('as_10:', as_conv10.shape)\n",
        "\n",
        "    as_conv11 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(4, 4), name='as_conv11')(as_conv10)\n",
        "    as_conv11 = BatchNormalization()(as_conv11)\n",
        "    as_conv11 = ReLU()(as_conv11)\n",
        "    print('as_11:', as_conv11.shape)\n",
        "\n",
        "    as_conv12 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(8, 8), name='as_conv12')(as_conv11)\n",
        "    as_conv12 = BatchNormalization()(as_conv12)\n",
        "    as_conv12 = ReLU()(as_conv12)\n",
        "    print('as_12:', as_conv12.shape)\n",
        "\n",
        "    as_conv13 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(16, 16), name='as_conv13')(as_conv12)\n",
        "    as_conv13 = BatchNormalization()(as_conv13)\n",
        "    as_conv13 = ReLU()(as_conv13)\n",
        "    print('as_13:', as_conv13.shape)\n",
        "\n",
        "    as_conv14 = Convolution2D(96, kernel_size=(5, 5), strides=(1, 1), padding='same', dilation_rate=(32, 32), name='as_conv14')(as_conv13)\n",
        "    as_conv14 = BatchNormalization()(as_conv14)\n",
        "    as_conv14 = ReLU()(as_conv14)\n",
        "    print('as_14:', as_conv14.shape)\n",
        "\n",
        "    as_conv15 = Convolution2D(8, kernel_size=(1, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='as_conv15')(as_conv14)\n",
        "    as_conv15 = BatchNormalization()(as_conv15)\n",
        "    as_conv15 = ReLU()(as_conv15)\n",
        "    print('as_15:', as_conv15.shape)\n",
        "\n",
        "    AS_out = Reshape((298, 8 * 257))(as_conv15)\n",
        "    print('AS_out:', AS_out.shape)\n",
        "    # --------------------------- AS end ---------------------------\n",
        "\n",
        "    # --------------------------- VS_model start ---------------------------\n",
        "    VS_model = Sequential()\n",
        "    VS_model.add(Convolution2D(512, kernel_size=(7, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='vs_conv1'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(512, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(1, 1), name='vs_conv2'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(512, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(2, 1), name='vs_conv3'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(512, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(4, 1), name='vs_conv4'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(512, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(8, 1), name='vs_conv5'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Convolution2D(512, kernel_size=(5, 1), strides=(1, 1), padding='same', dilation_rate=(16, 1), name='vs_conv6'))\n",
        "    VS_model.add(BatchNormalization())\n",
        "    VS_model.add(ReLU())\n",
        "    VS_model.add(Reshape((75, 512, 1)))\n",
        "    VS_model.add(UpSampling2DBilinear((298, 512)))\n",
        "    VS_model.add(Reshape((298, 512)))\n",
        "    # --------------------------- VS_model end ---------------------------\n",
        "\n",
        "    video_input = Input(shape=(75, 1, 1792, people_num))\n",
        "    AVfusion_list = [AS_out]\n",
        "    for i in range(people_num):\n",
        "        single_input = Lambda(sliced, arguments={'index': i})(video_input)\n",
        "        VS_out = VS_model(single_input)\n",
        "        AVfusion_list.append(VS_out)\n",
        "\n",
        "    AVfusion = concatenate(AVfusion_list, axis=2)\n",
        "    AVfusion = TimeDistributed(Flatten())(AVfusion)\n",
        "    print('AVfusion:', AVfusion.shape)\n",
        "\n",
        "    lstm = Bidirectional(LSTM(1024, input_shape=(298, 8 * 257), return_sequences=True), merge_mode='sum')(AVfusion)\n",
        "    print('lstm:', lstm.shape)\n",
        "\n",
        "    fc1 = Dense(1024, name=\"fc1\", activation='relu', kernel_initializer=he_normal(seed=27))(lstm)\n",
        "    print('fc1:', fc1.shape)\n",
        "    fc2 = Dense(1024, name=\"fc2\", activation='relu', kernel_initializer=he_normal(seed=42))(fc1)\n",
        "    print('fc2:', fc2.shape)\n",
        "    fc3 = Dense(1024, name=\"fc3\", activation='relu', kernel_initializer=he_normal(seed=65))(fc2)\n",
        "    print('fc3:', fc3.shape)\n",
        "\n",
        "    complex_mask = Dense(257 * 2 * people_num, name=\"complex_mask\", kernel_initializer=glorot_uniform(seed=87))(fc3)\n",
        "    print('complex_mask:', complex_mask.shape)\n",
        "\n",
        "    complex_mask_out = Reshape((298, 257, 2, people_num))(complex_mask)\n",
        "    print('complex_mask_out:', complex_mask_out.shape)\n",
        "\n",
        "    AV_model = Model(inputs=[audio_input, video_input], outputs=complex_mask_out)\n",
        "\n",
        "    # # compile AV_model\n",
        "    # AV_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return AV_model\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFP05WBJifwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82c163cd-1187-4e9e-deb7-9dacc2f3af19"
      },
      "source": [
        "from av_sep.models.lib import model_ops\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.models import load_model\n",
        "from av_sep.models.lib.MyGenerator import AVGenerator\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import optimizers\n",
        "import os\n",
        "from av_sep.models.lib.model_loss import audio_discriminate_loss2 as audio_loss\n",
        "import tensorflow as tf\n",
        "\n",
        "ROOTPATH = rootpath\n",
        "\n",
        "#############################################################\n",
        "# automatically change lr\n",
        "def scheduler(epoch):\n",
        "    ini_lr = 0.00001\n",
        "    lr = ini_lr\n",
        "    if epoch >= 5:\n",
        "        lr = ini_lr / 5\n",
        "    if epoch >= 10:\n",
        "        lr = ini_lr / 10\n",
        "    return lr\n",
        "\n",
        "# create AV model\n",
        "#############################################################\n",
        "RESTORE = False\n",
        "# If set true, continue training from last checkpoint\n",
        "# needed change 1:h5 file name, 2:epochs num, 3:initial_epoch\n",
        "\n",
        "# super parameters\n",
        "people_num = 2\n",
        "epochs = 50\n",
        "initial_epoch = 0\n",
        "batch_size = 4  # 4 to feed one 16G GPU\n",
        "gamma_loss = 0.1\n",
        "beta_loss = gamma_loss*2\n",
        "\n",
        "# physical devices option to accelerate training process\n",
        "workers = 1 # num of core\n",
        "use_multiprocessing = False\n",
        "NUM_GPU = 1\n",
        "\n",
        "# PATH\n",
        "path = ROOTPATH + 'saved_AV_models'  # model path\n",
        "database_dir_path = ROOTPATH\n",
        "#############################################################\n",
        "\n",
        "# create folder to save models\n",
        "folder = os.path.exists(path)\n",
        "if not folder:\n",
        "    os.makedirs(path)\n",
        "    print('create folder to save models')\n",
        "filepath = path + \"/AVmodel-\" + str(people_num) + \"p-{epoch:03d}-{val_loss:.5f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "\n",
        "rlr = LearningRateScheduler(scheduler, verbose=1)\n",
        "#############################################################\n",
        "# read train and val file name\n",
        "# format: mix.npy single.npy single.npy\n",
        "trainfile = []\n",
        "valfile = []\n",
        "with open((database_dir_path+'audio/AVdataset_train.txt'), 'r') as t:\n",
        "    trainfile = t.readlines()\n",
        "with open((database_dir_path+'audio/AVdataset_val.txt'), 'r') as v:\n",
        "    valfile = v.readlines()\n",
        "# ///////////////////////////////////////////////////////// #\n",
        "\n",
        "# the training steps\n",
        "if RESTORE:\n",
        "    latest_file = model_ops.latest_file(path+'/')\n",
        "    AV_model = load_model(latest_file,custom_objects={\"tf\": tf})\n",
        "    info = latest_file.strip().split('-')\n",
        "    initial_epoch = int(info[-2])\n",
        "else:\n",
        "    AV_model = AV_model(people_num)\n",
        "\n",
        "train_generator = AVGenerator(trainfile,database_dir_path= database_dir_path, batch_size=batch_size, shuffle=True)\n",
        "val_generator = AVGenerator(valfile,database_dir_path=database_dir_path, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "if NUM_GPU > 1:\n",
        "    parallel_model = model_ops.ModelMGPU(AV_model,NUM_GPU)\n",
        "    adam = optimizers.Adam()\n",
        "    loss = audio_loss(gamma=gamma_loss,beta=beta_loss,num_speaker=people_num)\n",
        "    parallel_model.compile(loss=loss,optimizer=adam)\n",
        "    print(AV_model.summary())\n",
        "    parallel_model.fit_generator(generator=train_generator,\n",
        "                            validation_data=val_generator,\n",
        "                            epochs=epochs,\n",
        "                            workers = workers,\n",
        "                            use_multiprocessing= use_multiprocessing,\n",
        "                            callbacks=[TensorBoard(log_dir='./log_AV'), checkpoint, rlr],\n",
        "                            initial_epoch=initial_epoch\n",
        "                            )\n",
        "if NUM_GPU <= 1:\n",
        "    adam = optimizers.Adam()\n",
        "    loss = audio_loss(gamma=gamma_loss,beta=beta_loss, num_speaker=people_num)\n",
        "    AV_model.compile(optimizer=adam, loss=loss)\n",
        "    print(AV_model.summary())\n",
        "    AV_model.fit_generator(generator=train_generator,\n",
        "                            validation_data=val_generator,\n",
        "                            epochs=epochs,\n",
        "                            workers = workers,\n",
        "                            use_multiprocessing= use_multiprocessing,\n",
        "                            callbacks=[TensorBoard(log_dir='./log_AV'), checkpoint, rlr],\n",
        "                            initial_epoch=initial_epoch\n",
        "                            )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as_0: (None, 298, 257, 2)\n",
            "as_1: (None, 298, 257, 96)\n",
            "as_2: (None, 298, 257, 96)\n",
            "as_3: (None, 298, 257, 96)\n",
            "as_4: (None, 298, 257, 96)\n",
            "as_5: (None, 298, 257, 96)\n",
            "as_6: (None, 298, 257, 96)\n",
            "as_7: (None, 298, 257, 96)\n",
            "as_8: (None, 298, 257, 96)\n",
            "as_9: (None, 298, 257, 96)\n",
            "as_10: (None, 298, 257, 96)\n",
            "as_11: (None, 298, 257, 96)\n",
            "as_12: (None, 298, 257, 96)\n",
            "as_13: (None, 298, 257, 96)\n",
            "as_14: (None, 298, 257, 96)\n",
            "as_15: (None, 298, 257, 8)\n",
            "AS_out: (None, 298, 2056)\n",
            "AVfusion: (None, 298, 3080)\n",
            "lstm: (None, 298, 1024)\n",
            "fc1: (None, 298, 1024)\n",
            "fc2: (None, 298, 1024)\n",
            "fc3: (None, 298, 1024)\n",
            "complex_mask: (None, 298, 1028)\n",
            "complex_mask_out: (None, 298, 257, 2, 2)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 298, 257, 2)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "as_conv1 (Conv2D)               (None, 298, 257, 96) 1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 298, 257, 96) 384         as_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv2 (Conv2D)               (None, 298, 257, 96) 64608       re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 298, 257, 96) 384         as_conv2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv3 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 298, 257, 96) 384         as_conv3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv4 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 298, 257, 96) 384         as_conv4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv5 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 298, 257, 96) 384         as_conv5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv6 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 298, 257, 96) 384         as_conv6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv7 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 298, 257, 96) 384         as_conv7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv8 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 298, 257, 96) 384         as_conv8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv9 (Conv2D)               (None, 298, 257, 96) 230496      re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 298, 257, 96) 384         as_conv9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 298, 257, 96) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "as_conv10 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 298, 257, 96) 384         as_conv10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv11 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 298, 257, 96) 384         as_conv11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv12 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 298, 257, 96) 384         as_conv12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv13 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 298, 257, 96) 384         as_conv13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv14 (Conv2D)              (None, 298, 257, 96) 230496      re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 298, 257, 96) 384         as_conv14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 298, 257, 96) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "as_conv15 (Conv2D)              (None, 298, 257, 8)  776         re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 298, 257, 8)  32          as_conv15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 75, 1, 1792,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 298, 257, 8)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 75, 1, 1792)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 75, 1, 1792)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 298, 2056)    0           re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 298, 512)     12991488    lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 298, 3080)    0           reshape_1[0][0]                  \n",
            "                                                                 sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 298, 3080)    0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 298, 1024)    33628160    time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 298, 1024)    1049600     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fc2 (Dense)                     (None, 298, 1024)    1049600     fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "fc3 (Dense)                     (None, 298, 1024)    1049600     fc2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "complex_mask (Dense)            (None, 298, 1028)    1053700     fc3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 298, 257, 2,  0           complex_mask[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 53,660,332\n",
            "Trainable params: 53,651,484\n",
            "Non-trainable params: 8,848\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 780 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2790/2790 [==============================] - 6756s 2s/step - loss: 0.5128 - val_loss: 0.4226\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.42258, saving model to /content/gdrive/My Drive/DL2/DL_AV_sep/data/saved_AV_models/AVmodel-2p-001-0.42258.h5\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 1e-05.\n",
            "2790/2790 [==============================] - 5952s 2s/step - loss: 0.4415 - val_loss: 0.4567\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.42258\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 1e-05.\n",
            "2790/2790 [==============================] - 5931s 2s/step - loss: 0.4212 - val_loss: 0.4292\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.42258\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 1e-05.\n",
            "2790/2790 [==============================] - 5794s 2s/step - loss: 0.4079 - val_loss: 0.3522\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.42258 to 0.35225, saving model to /content/gdrive/My Drive/DL2/DL_AV_sep/data/saved_AV_models/AVmodel-2p-004-0.35225.h5\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 1e-05.\n",
            "2790/2790 [==============================] - 5809s 2s/step - loss: 0.3980 - val_loss: 0.3439\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.35225 to 0.34394, saving model to /content/gdrive/My Drive/DL2/DL_AV_sep/data/saved_AV_models/AVmodel-2p-005-0.34394.h5\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "2790/2790 [==============================] - 5917s 2s/step - loss: 0.3911 - val_loss: 0.3541\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.34394\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "2790/2790 [==============================] - 5930s 2s/step - loss: 0.3888 - val_loss: 0.3813\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.34394\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "2790/2790 [==============================] - 5926s 2s/step - loss: 0.3866 - val_loss: 0.3680\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.34394\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "2790/2790 [==============================] - 5962s 2s/step - loss: 0.3844 - val_loss: 0.3697\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.34394\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 2.0000000000000003e-06.\n",
            "2790/2790 [==============================] - 5902s 2s/step - loss: 0.3820 - val_loss: 0.4144\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.34394\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "2790/2790 [==============================] - 5923s 2s/step - loss: 0.3800 - val_loss: 0.4102\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.34394\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
            "2789/2790 [============================>.] - ETA: 2s - loss: 0.3787"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2kXvRea_xsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}